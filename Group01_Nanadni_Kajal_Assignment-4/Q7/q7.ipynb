{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkMqwXcFXEUf","executionInfo":{"status":"ok","timestamp":1693390487373,"user_tz":-330,"elapsed":31982,"user":{"displayName":"Bhanu Sharma","userId":"12247066427796818681"}},"outputId":"c841de0f-064e-4809-a547-8f538ebfe8e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSBSW_dbSwiU","executionInfo":{"status":"ok","timestamp":1693390612548,"user_tz":-330,"elapsed":444,"user":{"displayName":"Bhanu Sharma","userId":"12247066427796818681"}},"outputId":"39bff87c-ad33-4bd3-8bb2-109073d99227"},"outputs":[{"output_type":"stream","name":"stdout","text":["drive  sample_data\n"]}],"source":["!ls\n"]},{"cell_type":"markdown","source":["%cd /content/drive/MyDrive/D22180_ACV/Group01_Nandani_Kajal_Assignment-3&4/Q7"],"metadata":{"id":"xpaeWkHtXRs0"}},{"cell_type":"code","source":["! git clone https://github.com/williamleif/GraphSAGE"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yaXnZ7w9Xdnc","executionInfo":{"status":"ok","timestamp":1693390618701,"user_tz":-330,"elapsed":2396,"user":{"displayName":"Bhanu Sharma","userId":"12247066427796818681"}},"outputId":"64c4fa00-1ecb-489b-904c-1600cd12c899"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'GraphSAGE'...\n","remote: Enumerating objects: 271, done.\u001b[K\n","remote: Counting objects: 100% (12/12), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 271 (delta 6), reused 0 (delta 0), pack-reused 259\u001b[K\n","Receiving objects: 100% (271/271), 6.43 MiB | 6.85 MiB/s, done.\n","Resolving deltas: 100% (164/164), done.\n"]}]},{"cell_type":"code","source":[" %cd /content/drive/MyDrive/CSIR_GL/GraphSAGE/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"158BRmFKZDmu","executionInfo":{"status":"ok","timestamp":1693390623533,"user_tz":-330,"elapsed":448,"user":{"displayName":"Bhanu Sharma","userId":"12247066427796818681"}},"outputId":"0eafaf01-3a55-41bd-877e-44401fdecae5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/CSIR_GL/GraphSAGE/'\n","/content\n"]}]},{"cell_type":"code","source":["!pip install --upgrade pip\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sa3_LKZXf0eL","executionInfo":{"status":"ok","timestamp":1694699524555,"user_tz":-330,"elapsed":9658,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"b247bbf8-0362-4f6c-cf52-bbb209098a93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Collecting pip\n","  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.1.2\n","    Uninstalling pip-23.1.2:\n","      Successfully uninstalled pip-23.1.2\n","Successfully installed pip-23.2.1\n"]}]},{"cell_type":"markdown","source":["\n","astor==0.6.2\n","backports.weakref==1.0.post1\n","bleach==1.5.0\n","decorator==4.3.0\n","enum34==1.1.6\n","funcsigs==1.0.2\n","futures\n","gast==0.2.0\n","grpcio==1.12.1\n","html5lib==0.9999999\n","Markdown==2.6.11\n","mock==2.0.0\n","networkx==1.11\n","numpy==1.14.5\n","pbr==4.0.4\n","protobuf==3.6.0\n","scikit-learn==0.19.1\n","scipy==1.1.0\n","six==1.11.0\n","sklearn==0.0\n","tensorboard\n","tensorflow\n","termcolor==1.1.0\n","Werkzeug==0.14.1"],"metadata":{"id":"02OGEjb_Gwwn"}},{"cell_type":"code","source":["!pip3 install -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQ3XcL89Y_Fv","executionInfo":{"status":"ok","timestamp":1691587086182,"user_tz":-330,"elapsed":210253,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"0d1aedfc-a147-40f2-84d8-3155ffe9b3bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 1)) (1.4.0)\n","Collecting astor==0.6.2 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 2))\n","  Using cached astor-0.6.2-py2.py3-none-any.whl (26 kB)\n","Collecting backports.weakref==1.0.post1 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 3))\n","  Using cached backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n","Collecting bleach==1.5.0 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 4))\n","  Using cached bleach-1.5.0-py2.py3-none-any.whl (17 kB)\n","Collecting decorator==4.3.0 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 5))\n","  Using cached decorator-4.3.0-py2.py3-none-any.whl (9.2 kB)\n","Collecting enum34==1.1.6 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 6))\n","  Using cached enum34-1.1.6-py3-none-any.whl (12 kB)\n","Collecting funcsigs (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 7))\n","  Using cached funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n","Collecting futures (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 8))\n","  Using cached futures-3.0.5.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gast==0.2.0 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 9))\n","  Using cached gast-0.2.0.tar.gz (9.4 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting grpcio==1.12.1 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 10))\n","  Using cached grpcio-1.12.1.tar.gz (14.2 MB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting html5lib==0.9999999 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 11))\n","  Using cached html5lib-0.9999999.tar.gz (889 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Markdown==2.6.11 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 12))\n","  Using cached Markdown-2.6.11-py2.py3-none-any.whl (78 kB)\n","Collecting mock==2.0.0 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 13))\n","  Using cached mock-2.0.0-py2.py3-none-any.whl (56 kB)\n","Collecting networkx==1.11 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 14))\n","  Using cached networkx-1.11-py2.py3-none-any.whl (1.3 MB)\n","Collecting numpy==1.14.5 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 15))\n","  Using cached numpy-1.14.5.zip (4.9 MB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pbr==4.0.4 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 16))\n","  Using cached pbr-4.0.4-py2.py3-none-any.whl (98 kB)\n","Collecting protobuf==3.6.0 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 17))\n","  Using cached protobuf-3.6.0-py2.py3-none-any.whl (390 kB)\n","Collecting scikit-learn==0.19.1 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 18))\n","  Using cached scikit-learn-0.19.1.tar.gz (9.5 MB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting scipy==1.1.0 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 19))\n","  Using cached scipy-1.1.0.tar.gz (15.6 MB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting six==1.11.0 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 20))\n","  Using cached six-1.11.0-py2.py3-none-any.whl (10 kB)\n","Collecting sklearn==0.0 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 21))\n","  Using cached sklearn-0.0.tar.gz (1.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 22)) (2.12.3)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 23)) (2.12.0)\n","Collecting termcolor==1.1.0 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 24))\n","  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Werkzeug==0.14.1 (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 25))\n","  Using cached Werkzeug-0.14.1-py2.py3-none-any.whl (322 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from protobuf==3.6.0->-r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 17)) (67.7.2)\n","INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorboard (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 22))\n","  Obtaining dependency information for tensorboard from https://files.pythonhosted.org/packages/bc/a2/ff5f4c299eb37c95299a76015da3f30211468e29d8d6f1d011683279baee/tensorboard-2.14.0-py3-none-any.whl.metadata\n","  Using cached tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n","  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n","  Using cached tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n","  Using cached tensorboard-2.12.1-py3-none-any.whl (5.6 MB)\n","  Using cached tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n","  Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n","  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n","INFO: pip is still looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n","  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","  Using cached tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n","  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n","  Using cached tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n","  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Using cached tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n","  Using cached tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n","  Using cached tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n","  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n","  Using cached tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n","  Using cached tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n","  Using cached tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n","  Using cached tensorboard-2.2.1-py3-none-any.whl (3.0 MB)\n","  Using cached tensorboard-2.2.0-py3-none-any.whl (2.8 MB)\n","  Using cached tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n","  Using cached tensorboard-2.1.0-py3-none-any.whl (3.8 MB)\n","  Using cached tensorboard-2.0.2-py3-none-any.whl (3.8 MB)\n","  Using cached tensorboard-2.0.1-py3-none-any.whl (3.8 MB)\n","  Using cached tensorboard-2.0.0-py3-none-any.whl (3.8 MB)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 22)) (0.41.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 23)) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 23)) (23.5.26)\n","INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 23))\n","  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/5a/f2/5c2f878c62c8b79c629b11b33516bb55054d7677eba6f56f3a20296b56bd/tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Using cached tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/5a/eb/912d970b667fa8884199eb7cc2c351b86f8c73ea3d57a161ea91547c5d3b/tensorflow-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Using cached tensorflow-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","  Using cached tensorflow-2.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","  Using cached tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","  Using cached tensorflow-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","  Using cached tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","  Using cached tensorflow-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n","Collecting flatbuffers<2,>=1.12 (from tensorflow->-r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 23))\n","  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","INFO: pip is still looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow (from -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 23))\n","  Using cached tensorflow-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n","  Using cached tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","  Using cached tensorflow-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","  Using cached tensorflow-2.8.4-cp310-cp310-manylinux2010_x86_64.whl (498.1 MB)\n","  Using cached tensorflow-2.8.3-cp310-cp310-manylinux2010_x86_64.whl (498.5 MB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Using cached tensorflow-2.8.2-cp310-cp310-manylinux2010_x86_64.whl (498.0 MB)\n","  Using cached tensorflow-2.8.1-cp310-cp310-manylinux2010_x86_64.whl (498.0 MB)\n","  Using cached tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n","\u001b[31mERROR: Cannot install -r /content/drive/MyDrive/CSIR_GL/GraphSAGE/requirements.txt (line 23), gast==0.2.0 and tensorflow==2.12.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n","\u001b[0m\n","The conflict is caused by:\n","    The user requested gast==0.2.0\n","    tensorflow 2.12.0 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.13.0 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.12.1 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.11.1 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.11.0 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.10.1 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.10.0 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.9.3 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.9.2 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.9.1 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.9.0 depends on gast<=0.4.0 and >=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.8.4 depends on gast>=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.8.3 depends on gast>=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.8.2 depends on gast>=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.8.1 depends on gast>=0.2.1\n","    The user requested gast==0.2.0\n","    tensorflow 2.8.0 depends on gast>=0.2.1\n","\n","To fix this you could try to:\n","1. loosen the range of package versions you've specified\n","2. remove package versions to allow pip attempt to solve the dependency conflict\n","\n","\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["https://github.com/gordicaleksa/pytorch-GAT"],"metadata":{"id":"6hUUDkThpKTF"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/D22180_ACV/Group01_Nandani_Kajal_Assignment-3&4/Q7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6eqKJWso7LC","executionInfo":{"status":"ok","timestamp":1693384367252,"user_tz":-330,"elapsed":8,"user":{"displayName":"Matruprasad Mohanty","userId":"18235090181230305398"}},"outputId":"26a696e3-982b-401d-c269-1439ff223260"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/Sharedwithme/CSIR_GL'\n","/content\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"a5GXQ0_ijVg9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"1YmgpyqJjThS"}},{"cell_type":"code","source":["!git clone https://github.com/gordicaleksa/pytorch-GAT"],"metadata":{"id":"RcQ1oP4sfGUh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691590344064,"user_tz":-330,"elapsed":4473,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"c7d8babb-1a46-4074-c5ce-6f26222ef61a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pytorch-GAT'...\n","remote: Enumerating objects: 634, done.\u001b[K\n","remote: Counting objects: 100% (144/144), done.\u001b[K\n","remote: Compressing objects: 100% (16/16), done.\u001b[K\n","remote: Total 634 (delta 135), reused 128 (delta 128), pack-reused 490\u001b[K\n","Receiving objects: 100% (634/634), 24.23 MiB | 11.13 MiB/s, done.\n","Resolving deltas: 100% (345/345), done.\n"]}]},{"cell_type":"markdown","source":["https://github.com/tkipf/gcn"],"metadata":{"id":"9gMqQa0Eezik"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/D22180_ACV/Group01_Nandani_Kajal_Assignment-3&4/Q7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WKXe1BTAe5iz","executionInfo":{"status":"ok","timestamp":1691872907737,"user_tz":-330,"elapsed":717,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"382579e4-c2de-4d7b-e0b4-610693811795"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CSIR_GL\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/tkipf/gcn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nKVdTzXKe0p0","executionInfo":{"status":"ok","timestamp":1691872913108,"user_tz":-330,"elapsed":2145,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"80dce50d-9ec5-4e1f-d1e9-9dd85f9b5b8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'gcn'...\n","remote: Enumerating objects: 176, done.\u001b[K\n","remote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 176 (delta 2), reused 1 (delta 0), pack-reused 167\u001b[K\n","Receiving objects: 100% (176/176), 5.09 MiB | 10.20 MiB/s, done.\n","Resolving deltas: 100% (85/85), done.\n"]}]},{"cell_type":"code","source":["%cd gcn\n"],"metadata":{"id":"paRdvhc3e_-F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd gcn"],"metadata":{"id":"gMMEEOz8k73z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python inits.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdxTWr9uk_VW","executionInfo":{"status":"ok","timestamp":1694689788733,"user_tz":-330,"elapsed":32,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"1c72500c-3771-4feb-f2ec-43b9bafe246d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file '/content/inits.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"code","source":["pip install --upgrade scipy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Yd9UYqGnMUI","executionInfo":{"status":"ok","timestamp":1691875246603,"user_tz":-330,"elapsed":7527,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"a9c1e70a-3af8-41cb-9ce3-5f7a74c3791d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.1)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from scipy.sparse.linalg import eigsh\n"],"metadata":{"id":"MlPUokl0nZcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python utils.py"],"metadata":{"id":"gcpaPqMvmojT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0cazqzolURK","executionInfo":{"status":"ok","timestamp":1691875351521,"user_tz":-330,"elapsed":7707,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"638e8c8c-3080-4021-b3ce-573302b051c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-08-12 21:22:24.092158: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-08-12 21:22:26.215885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/CSIR_GL/gcn/gcn/train.py\", line 7, in <module>\n","    from gcn.utils import *\n","ModuleNotFoundError: No module named 'gcn.utils'\n"]}]},{"cell_type":"markdown","source":["https://github.com/tkipf/pygcn.git"],"metadata":{"id":"f6hjaEZKIoc3"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/D22180_ACV/Group01_Nandani_Kajal_Assignment-3&4/Q7"],"metadata":{"id":"dJxt2tLuIx8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/tkipf/pygcn.git"],"metadata":{"id":"E8aYlJiQMUPU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691665759198,"user_tz":-330,"elapsed":1536,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"4faeac83-12b9-4bd4-ff95-062853b5ba43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pygcn'...\n","remote: Enumerating objects: 78, done.\u001b[K\n","remote: Total 78 (delta 0), reused 0 (delta 0), pack-reused 78\u001b[K\n","Receiving objects: 100% (78/78), 226.61 KiB | 2.80 MiB/s, done.\n","Resolving deltas: 100% (35/35), done.\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/D22180_ACV/Group01_Nandani_Kajal_Assignment-3&4/Q7/pygcn"],"metadata":{"id":"vn_HXkG8JJy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd pygcn"],"metadata":{"id":"csfnlYEvcc4l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python __init__.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HUpoiDYOcnaG","executionInfo":{"status":"ok","timestamp":1691872356045,"user_tz":-330,"elapsed":1146,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"d270747c-68e1-4833-994f-ec2cc0d2d6ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/CSIR_GL/pygcn/pygcn/__init__.py\", line 4, in <module>\n","    from .layers import *\n","ImportError: attempted relative import with no known parent package\n"]}]},{"cell_type":"code","source":["!python layers.py"],"metadata":{"id":"8gVciSA7JALz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install pygcn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qwdii8endJLn","executionInfo":{"status":"ok","timestamp":1691872599213,"user_tz":-330,"elapsed":9789,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"c97a327f-a49c-45bd-f7fe-694340ef1cf4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pygcn in /usr/local/lib/python3.10/dist-packages (1.1.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pygcn) (4.9.3)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["pip install --upgrade pip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZE5wN4J9dwIq","executionInfo":{"status":"ok","timestamp":1691872626524,"user_tz":-330,"elapsed":8273,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"7ed4dad3-13e4-4b26-9cc1-cbc10862acb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.2.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!python models.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z6oDNGJTdBn-","executionInfo":{"status":"ok","timestamp":1691872632073,"user_tz":-330,"elapsed":2493,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"7dc3a210-b293-4ab0-95f1-ffdb339c6226"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/CSIR_GL/pygcn/pygcn/models.py\", line 3, in <module>\n","    from pygcn.layers import GraphConvolution\n","ModuleNotFoundError: No module named 'pygcn'\n"]}]},{"cell_type":"code","source":["!python train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7uzdlhbJDe6","executionInfo":{"status":"ok","timestamp":1691666165878,"user_tz":-330,"elapsed":1964,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"0d287311-b84f-4d9b-8747-3ec5b53f7df7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/CSIR_GL/pygcn/pygcn/train.py\", line 12, in <module>\n","    from pygcn.utils import load_data, accuracy\n","ModuleNotFoundError: No module named 'pygcn'\n"]}]},{"cell_type":"markdown","source":["https://github.com/senadkurtisi/pytorch-GCN/tree/main"],"metadata":{"id":"BmtUUhz4QdyW"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/D22180_ACV/Group01_Nandani_Kajal_Assignment-3&4/Q7/\n"],"metadata":{"id":"KMNh6n5wJ-1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd pytorch-GCN-main\n"],"metadata":{"id":"nUT3sX-mQj2-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd src\n"],"metadata":{"id":"3sXqjW7gR_8_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install igraph"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MPdJDEqMSTtB","executionInfo":{"status":"ok","timestamp":1691871785901,"user_tz":-330,"elapsed":5826,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"090d5c73-2f92-4fd5-f350-1d6146ed9daf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: igraph in /usr/local/lib/python3.10/dist-packages (0.10.6)\n","Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph) (1.6.7)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!sudo apt-get install libcairo2-dev"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tHCrFIpgTOQd","executionInfo":{"status":"ok","timestamp":1691871791264,"user_tz":-330,"elapsed":2244,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"dfa872b6-2ef3-4c85-ebc6-ad5db31e1b9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libcairo2-dev is already the newest version (1.16.0-5ubuntu2).\n","0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n"]}]},{"cell_type":"code","source":["pip install --upgrade pip setuptools"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqmqhFTqTcVA","executionInfo":{"status":"ok","timestamp":1691871813740,"user_tz":-330,"elapsed":14874,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"b7d562f7-c2d7-43b2-ac93-dac5994ef3bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.2.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (68.0.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["pip install --upgrade pip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S7GruVxETplc","executionInfo":{"status":"ok","timestamp":1691871827327,"user_tz":-330,"elapsed":8057,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"25b573db-e253-4cbd-c039-8f2bd44ce849"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.2.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["pip install cairocffi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xR7Z2lkaUHpX","executionInfo":{"status":"ok","timestamp":1691871836849,"user_tz":-330,"elapsed":9529,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"7977d82b-9307-49eb-c9ec-daa3b0b6d3e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting cairocffi\n","  Obtaining dependency information for cairocffi from https://files.pythonhosted.org/packages/17/be/a5d2c16317c6a890502725970589ae7f06cfc66b2e6916ba0a86973403c8/cairocffi-1.6.1-py3-none-any.whl.metadata\n","  Downloading cairocffi-1.6.1-py3-none-any.whl.metadata (3.3 kB)\n","Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cairocffi) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n","Downloading cairocffi-1.6.1-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: cairocffi\n","Successfully installed cairocffi-1.6.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import cairocffi"],"metadata":{"id":"HB862RWbUU5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python main.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tCZwBNgeRdo3","executionInfo":{"status":"ok","timestamp":1693383923043,"user_tz":-330,"elapsed":770,"user":{"displayName":"Matruprasad Mohanty","userId":"18235090181230305398"}},"outputId":"c4b4aeb4-c50f-4fab-fbc5-db92e025d8d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file '/content/main.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"code","source":["!pip install scipy scikit-learn\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_5WWy7v2sAw","executionInfo":{"status":"ok","timestamp":1691946250490,"user_tz":-330,"elapsed":8823,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"bb073938-697a-4b90-d086-cde5765f8c8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"]}]},{"cell_type":"code","source":["!pip install --upgrade pip\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WE19r3sR2xVB","executionInfo":{"status":"ok","timestamp":1691946281666,"user_tz":-330,"elapsed":18276,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"e0383f95-a04e-4a67-bd15-aa4535ed19f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Collecting pip\n","  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.1.2\n","    Uninstalling pip-23.1.2:\n","      Successfully uninstalled pip-23.1.2\n","Successfully installed pip-23.2.1\n"]}]},{"cell_type":"code","source":["pip install scipy scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqnu5EGU2UF8","executionInfo":{"status":"ok","timestamp":1691946385024,"user_tz":-330,"elapsed":8068,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"2d462226-e497-4c5b-a7d8-dcb94beae9a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","import networkx as nx\n","import scipy.sparse as sp"],"metadata":{"id":"-IRww14r3cQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pickle as pkl\n","import networkx as nx\n","import scipy.sparse as sp\n","#from scipy.sparse.linalg.eigen.arpack import eigsh\n","import sys\n","\n","\n","def parse_index_file(filename):\n","    \"\"\"Parse index file.\"\"\"\n","    index = []\n","    for line in open(filename):\n","        index.append(int(line.strip()))\n","    return index\n","\n","\n","def sample_mask(idx, l):\n","    \"\"\"Create mask.\"\"\"\n","    mask = np.zeros(l)\n","    mask[idx] = 1\n","    return np.array(mask, dtype=np.bool)\n","\n","\n","def load_data(dataset_str):\n","    \"\"\"\n","    Loads input data from gcn/data directory\n","\n","    ind.dataset_str.x => the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;\n","    ind.dataset_str.tx => the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;\n","    ind.dataset_str.allx => the feature vectors of both labeled and unlabeled training instances\n","        (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;\n","    ind.dataset_str.y => the one-hot labels of the labeled training instances as numpy.ndarray object;\n","    ind.dataset_str.ty => the one-hot labels of the test instances as numpy.ndarray object;\n","    ind.dataset_str.ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n","    ind.dataset_str.graph => a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict\n","        object;\n","    ind.dataset_str.test.index => the indices of test instances in graph, for the inductive setting as list object.\n","\n","    All objects above must be saved using python pickle module.\n","\n","    :param dataset_str: Dataset name\n","    :return: All data input files loaded (as well the training/test data).\n","    \"\"\"\n","    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n","    objects = []\n","    for i in range(len(names)):\n","        with open(\"data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n","            if sys.version_info > (3, 0):\n","                objects.append(pkl.load(f, encoding='latin1'))\n","            else:\n","                objects.append(pkl.load(f))\n","\n","    x, y, tx, ty, allx, ally, graph = tuple(objects)\n","    test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset_str))\n","    test_idx_range = np.sort(test_idx_reorder)\n","\n","    if dataset_str == 'citeseer':\n","        # Fix citeseer dataset (there are some isolated nodes in the graph)\n","        # Find isolated nodes, add them as zero-vecs into the right position\n","        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n","        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n","        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n","        tx = tx_extended\n","        ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n","        ty_extended[test_idx_range-min(test_idx_range), :] = ty\n","        ty = ty_extended\n","\n","    features = sp.vstack((allx, tx)).tolil()\n","    features[test_idx_reorder, :] = features[test_idx_range, :]\n","    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n","\n","    labels = np.vstack((ally, ty))\n","    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n","\n","    idx_test = test_idx_range.tolist()\n","    idx_train = range(len(y))\n","    idx_val = range(len(y), len(y)+500)\n","\n","    train_mask = sample_mask(idx_train, labels.shape[0])\n","    val_mask = sample_mask(idx_val, labels.shape[0])\n","    test_mask = sample_mask(idx_test, labels.shape[0])\n","\n","    y_train = np.zeros(labels.shape)\n","    y_val = np.zeros(labels.shape)\n","    y_test = np.zeros(labels.shape)\n","    y_train[train_mask, :] = labels[train_mask, :]\n","    y_val[val_mask, :] = labels[val_mask, :]\n","    y_test[test_mask, :] = labels[test_mask, :]\n","\n","    return adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask\n","\n","\n","def sparse_to_tuple(sparse_mx):\n","    \"\"\"Convert sparse matrix to tuple representation.\"\"\"\n","    def to_tuple(mx):\n","        if not sp.isspmatrix_coo(mx):\n","            mx = mx.tocoo()\n","        coords = np.vstack((mx.row, mx.col)).transpose()\n","        values = mx.data\n","        shape = mx.shape\n","        return coords, values, shape\n","\n","    if isinstance(sparse_mx, list):\n","        for i in range(len(sparse_mx)):\n","            sparse_mx[i] = to_tuple(sparse_mx[i])\n","    else:\n","        sparse_mx = to_tuple(sparse_mx)\n","\n","    return sparse_mx\n","\n","\n","def preprocess_features(features):\n","    \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n","    rowsum = np.array(features.sum(1))\n","    r_inv = np.power(rowsum, -1).flatten()\n","    r_inv[np.isinf(r_inv)] = 0.\n","    r_mat_inv = sp.diags(r_inv)\n","    features = r_mat_inv.dot(features)\n","    return sparse_to_tuple(features)\n","\n","\n","def normalize_adj(adj):\n","    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n","    adj = sp.coo_matrix(adj)\n","    rowsum = np.array(adj.sum(1))\n","    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n","    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n","    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n","    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n","\n","\n","def preprocess_adj(adj):\n","    \"\"\"Preprocessing of adjacency matrix for simple GCN model and conversion to tuple representation.\"\"\"\n","    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n","    return sparse_to_tuple(adj_normalized)\n","\n","\n","def construct_feed_dict(features, support, labels, labels_mask, placeholders):\n","    \"\"\"Construct feed dictionary.\"\"\"\n","    feed_dict = dict()\n","    feed_dict.update({placeholders['labels']: labels})\n","    feed_dict.update({placeholders['labels_mask']: labels_mask})\n","    feed_dict.update({placeholders['features']: features})\n","    feed_dict.update({placeholders['support'][i]: support[i] for i in range(len(support))})\n","    feed_dict.update({placeholders['num_features_nonzero']: features[1].shape})\n","    return feed_dict\n","\n","\n","def chebyshev_polynomials(adj, k):\n","    \"\"\"Calculate Chebyshev polynomials up to order k. Return a list of sparse matrices (tuple representation).\"\"\"\n","    print(\"Calculating Chebyshev polynomials up to order {}...\".format(k))\n","\n","    adj_normalized = normalize_adj(adj)\n","    laplacian = sp.eye(adj.shape[0]) - adj_normalized\n","    largest_eigval, _ = eigsh(laplacian, 1, which='LM')\n","    scaled_laplacian = (2. / largest_eigval[0]) * laplacian - sp.eye(adj.shape[0])\n","\n","    t_k = list()\n","    t_k.append(sp.eye(adj.shape[0]))\n","    t_k.append(scaled_laplacian)\n","\n","    def chebyshev_recurrence(t_k_minus_one, t_k_minus_two, scaled_lap):\n","        s_lap = sp.csr_matrix(scaled_lap, copy=True)\n","        return 2 * s_lap.dot(t_k_minus_one) - t_k_minus_two\n","\n","    for i in range(2, k+1):\n","        t_k.append(chebyshev_recurrence(t_k[-1], t_k[-2], scaled_laplacian))\n","\n","    return sparse_to_tuple(t_k)"],"metadata":{"id":"NBdu6me42LO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Set random seed\n","seed = 123\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","\n","# Load data\n","dataset = \"/content/drive/MyDrive/D22180_ACV/Group01_Nandani_Kajal_Assignment-3&4/Q7/gcn/gcn/data/ind.cora.x\"  # Change this to the dataset you want to use\n","adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(dataset)\n","\n","# Preprocessing\n","adj_normalized = preprocess_adj(adj)\n","features = preprocess_features(features)\n","\n","# Define placeholders\n","placeholders = {\n","    'support': [tf.sparse_placeholder(tf.float32) for _ in range(1)],\n","    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n","    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n","    'labels_mask': tf.placeholder(tf.int32),\n","    'dropout': tf.placeholder_with_default(0., shape=()),\n","    'num_features_nonzero': tf.placeholder(tf.int32)\n","}\n"],"metadata":{"id":"To14q7yK3diT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","\n","from gcn.utils import load_data, preprocess_features, preprocess_adj, construct_feed_dict, sparse_to_tuple\n","from gcn.models import GCN\n","\n","# Set random seed\n","seed = 123\n","np.random.seed(seed)\n","tf.set_random_seed(seed)\n","\n","# Load data\n","dataset = \"/content/drive/MyDrive/D22180_ACV/Group01_Nandani_Kajal_Assignment-3&4/Q7/gcn/gcn/data\"  # Change this to the dataset you want to use\n","adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(dataset)\n","\n","# Preprocessing\n","adj_normalized = preprocess_adj(adj)\n","features = preprocess_features(features)\n","\n","# Define placeholders\n","placeholders = {\n","    'support': [tf.sparse_placeholder(tf.float32) for _ in range(1)],\n","    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n","    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n","    'labels_mask': tf.placeholder(tf.int32),\n","    'dropout': tf.placeholder_with_default(0., shape=()),\n","    'num_features_nonzero': tf.placeholder(tf.int32)\n","}\n","\n","# Create GCN model\n","model = GCN(placeholders, input_dim=features[2][1], logging=True)\n","\n","# Initialize session\n","sess = tf.Session()\n","\n","# Initialize variables\n","sess.run(tf.global_variables_initializer())\n","\n","# Train and evaluate GCN model\n","epochs = 200\n","for epoch in range(epochs):\n","    feed_dict = construct_feed_dict(features, [adj_normalized], y_train, train_mask, placeholders)\n","    feed_dict.update({placeholders['dropout']: 0.5})  # Dropout rate\n","\n","    # Training step\n","    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n","\n","    # Validation\n","    val_loss, val_acc = sess.run([model.loss, model.accuracy],\n","                                 feed_dict=construct_feed_dict(features, [adj_normalized], y_val, val_mask, placeholders))\n","\n","    print(f\"Epoch {epoch + 1}/{epochs} - Train loss: {outs[1]:.4f}, Train accuracy: {outs[2]:.4f}, \"\n","          f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_acc:.4f}\")\n","\n","print(\"Training finished!\")\n","\n","# Testing\n","test_loss, test_acc = sess.run([model.loss, model.accuracy],\n","                               feed_dict=construct_feed_dict(features, [adj_normalized], y_test, test_mask, placeholders))\n","print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n","\n","sess.close()\n"],"metadata":{"id":"ddbx6OEb1DNT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["https://github.com/WilliamCCHuang/GraphLIME/tree/master"],"metadata":{"id":"D-cSj1cykWmJ"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/D22180_ACV/Group01_Nandani_Kajal_Assignment-3&4/Q7"],"metadata":{"id":"Hki2oJKpkzbm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/WilliamCCHuang/GraphLIME\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97PiHSFzkavo","executionInfo":{"status":"ok","timestamp":1693367650917,"user_tz":-330,"elapsed":1539,"user":{"displayName":"Nandani Sharma","userId":"09138883666819120518"}},"outputId":"3a0e89c7-4cf6-49ab-b659-33daa2eacb8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'GraphLIME'...\n","remote: Enumerating objects: 247, done.\u001b[K\n","remote: Counting objects: 100% (247/247), done.\u001b[K\n","remote: Compressing objects: 100% (177/177), done.\u001b[K\n","remote: Total 247 (delta 112), reused 176 (delta 58), pack-reused 0\u001b[K\n","Receiving objects: 100% (247/247), 629.67 KiB | 6.56 MiB/s, done.\n","Resolving deltas: 100% (112/112), done.\n"]}]}]}